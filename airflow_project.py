# -*- coding: utf-8 -*-
"""Airflow_Project.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JZ1aClGAjxs1fRmoi9OhIIqSKCsnkCid
"""

from datetime import timedelta, datetime

from airflow import DAG
from airflow.providers.google.cloud.operators.bigquery import BigQueryCheckOperator, BigQueryInsertJobOperator

default_args = {
    'owner': 'airflow',
    'depends_on_past': True,
    'start_date' : datetime(2024, 6, 1),
    'email': ['andre@admazes.com'],
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=2),
}

dag = DAG(
    'Bitcoin_Dogecoin_Correlation',
    default_args=default_args,
    description='calculation of DOGE coins size per transaction',
    #schedule_interval = '@hourly',
    schedule_interval = '00 05 * * *'
)

#Doge
t1 = BigQueryCheckOperator(
    task_id='bq_check_doge_data',
    sql = '''
    select
    block_timestamp,
    from bigquery-public-data.crypto_dogecoin.transactions
    where block_timestamp = '2013-12-06 10:25:40 UTC'
    limit 1000
        ''',
    use_legacy_sql=False,
    dag = dag
)

#Bitcoin
t2 = BigQueryCheckOperator(
    task_id ='bq_check_bitcoin_data',
    sql = '''
    select
    block_timestamp,
    from bigquery-public-data.crypto_bitcoin.transactions
    where block_timestamp = '2009-01-03 18:15:05 UTC'
    limit 1000
    ''',
    use_legacy_sql=False,
    dag = dag
)

#weather
t3 = BigQueryCheckOperator(
    task_id ='bq_check_weather_data',
    sql = '''
    select
    date,
    from bigquery-public-data.noaa_gsod.gsod2024
    where date = '2024-01-01'
    limit 1000
    ''',
    use_legacy_sql=False,
    dag = dag
)

t4_query = f"""
SELECT
  FORMAT_TIMESTAMP("%Y%m%d", block_timestamp) AS Transaction_date,
  ROUND(SUM(output_count/1000000),2) AS Dogecoin_transaction_count_million,
  ROUND(SUM(size)/1000000,2) AS Dogecoin_transaction_size_million,
  ROUND((SUM(output_value)/1000000),0) AS Dogecoin_transaction_value_million
FROM
  `bigquery-public-data.crypto_dogecoin.transactions`
WHERE
    CAST(FORMAT_TIMESTAMP("%Y%m%d", block_timestamp) AS STRING) = "{{{{ ds_nodash }}}}"
GROUP BY
  Transaction_date
ORDER BY
  Transaction_date DESC
LIMIT
  1
"""
t4 = BigQueryInsertJobOperator(
    task_id="Query_Dogecoin",
    dag=dag,
    configuration={
        "query":{
            "query": t4_query,
            "writeDisposition": "WRITE_APPEND",
            "use_legacy_sql": False,
            "destinationTable":{
                "projectId": "admazes-da-intern-gcp-dev-2024",
                "datasetId": "airflow_project",
                "tableId": "Dogecoin_Query_Data"
            }
        }
    }
) #Doge

t5_query = f"""
SELECT
  FORMAT_TIMESTAMP("%Y%m%d", block_timestamp) AS Transaction_date,
  ROUND(SUM(output_count/1000000),2) AS Bitcoin_transaction_count_million,
  ROUND(SUM(size)/1000000,2) AS Bitcoin_transaction_size_million,
  ROUND((SUM(output_value)/1000000),0) AS Bitcoin_transaction_value_million
FROM
  `bigquery-public-data.crypto_bitcoin.transactions`
WHERE
  CAST(FORMAT_TIMESTAMP("%Y%m%d", block_timestamp) AS STRING) = "{{{{ ds_nodash }}}}"
GROUP BY
  Transaction_date
ORDER BY
  Transaction_date DESC
LIMIT
  1
"""
t5 = BigQueryInsertJobOperator(
    task_id="Query_Bitcoin",
    dag=dag,
    configuration={
        "query":{
            "query": t5_query,
            "writeDisposition": "WRITE_APPEND",
            "use_legacy_sql": False,
            "destinationTable":{
                "projectId": "admazes-da-intern-gcp-dev-2024",
                "datasetId": "airflow_project",
                "tableId": "Bitcoin_Query_Data"
            }
        }
    }
)#Bitcoin

t6_query =f"""
SELECT
  CAST(FORMAT_DATE("%Y%m%d", `date`) AS STRING) AS weather_date,
  temp AS Temperature,
  rain_drizzle AS Rain
FROM
  bigquery-public-data.noaa_gsod.gsod2024
WHERE
  stn = "010010" AND
  CAST(FORMAT_DATE("%Y%m%d", `date`) AS STRING) = "{{{{ ds_nodash }}}}"
"""
t6 = BigQueryInsertJobOperator(
    task_id="Query_Weather",
    dag=dag,
    configuration={
        "query":{
            "query": t6_query,
            "writeDisposition": "WRITE_APPEND",
            "use_legacy_sql": False,
            "destinationTable":{
                "projectId": "admazes-da-intern-gcp-dev-2024",
                "datasetId": "airflow_project",
                "tableId": "Weather_Query_Data"
            }
        }
    }
)#Bitcoin

#Join the table together
t7_query = f'''
SELECT
        Weather_Query_Data.weather_date,
        Weather_Query_Data.Temperature,
        Weather_Query_Data.Rain,
        bitcoin_query.Transaction_date AS Transaction_date,
        doge_query.Transaction_date AS Dogecoin_Transaction_date,
        Dogecoin_transaction_size_million,
        Bitcoin_transaction_count_million,
        Dogecoin_transaction_count_million,
        Bitcoin_transaction_size_million,
        Dogecoin_transaction_value_million,
        Bitcoin_transaction_value_million
    FROM
        admazes-da-intern-gcp-dev-2024.airflow_project.Bitcoin_Query_Data AS bitcoin_query
    LEFT JOIN
        admazes-da-intern-gcp-dev-2024.airflow_project.Dogecoin_Query_Data AS doge_query
        ON bitcoin_query.Transaction_date = doge_query.Transaction_date
    LEFT JOIN
        admazes-da-intern-gcp-dev-2024.airflow_project.Weather_Query_Data
        ON doge_query.Transaction_date = Weather_Query_Data.weather_date
       WHERE
        bitcoin_query.Transaction_date = "{{{{ ds_nodash }}}}"
      order by Transaction_date
    '''
t7 = BigQueryInsertJobOperator(
     task_id="combine_table",
     dag=dag,
      configuration={
         "query":{
             "query": t7_query,
             "writeDisposition": "WRITE_APPEND",
             "use_legacy_sql": False,
              "destinationTable":{
                 "projectId": "admazes-da-intern-gcp-dev-2024",
                 "datasetId": "airflow_project",
                 "tableId": "comb_table_data"
              }
          }
      }
  )

#t7 = BigQueryCheckOperator #Check the joined table
t8 = BigQueryCheckOperator(
    task_id ='bq_check_comb_table_data',
    sql = '''
   select
    Bitcoin_transaction_value_million
from admazes-da-intern-gcp-dev-2024.airflow_project.comb_table_data
limit 1000
    ''',
    use_legacy_sql=False,
    dag = dag
)

t9_query = f"""
select
Transaction_date,
Bitcoin_transaction_count_million,
Dogecoin_transaction_count_million,
Bitcoin_transaction_size_million,
Dogecoin_transaction_size_million,
Dogecoin_transaction_value_million,
Bitcoin_transaction_value_million,
Temperature,
Rain,
CASE
WHEN LAG(Dogecoin_transaction_count_million) OVER (ORDER BY Transaction_date) IS NULL THEN NULL
ELSE round((Dogecoin_transaction_count_million - LAG(Dogecoin_transaction_count_million) OVER (ORDER BY Transaction_date)) /LAG(Dogecoin_transaction_count_million) OVER (ORDER BY Transaction_date),3)
END AS percentage_change_of_doge_trans_count_mil,
CASE
WHEN LAG(Bitcoin_transaction_count_million) OVER (ORDER BY Transaction_date) IS NULL THEN NULL
ELSE round((Bitcoin_transaction_count_million - LAG(Bitcoin_transaction_count_million) OVER (ORDER BY Transaction_date)) /LAG(Bitcoin_transaction_count_million)OVER (ORDER BY Transaction_date),3)
END AS percentage_change_of_Bitcoin_trans_count_mil,
CASE
WHEN LAG(Dogecoin_transaction_size_million) OVER (ORDER BY Transaction_date) IS NULL THEN NULL
ELSE round((Dogecoin_transaction_size_million - LAG(Dogecoin_transaction_size_million) OVER (ORDER BY Transaction_date)) /LAG(Dogecoin_transaction_size_million) OVER (ORDER BY Transaction_date),3)
END AS percentage_change_of_doge_trans_size_mil,
CASE
WHEN LAG(Bitcoin_transaction_size_million) OVER (ORDER BY Transaction_date) IS NULL THEN NULL
ELSE round((Bitcoin_transaction_size_million - LAG(Bitcoin_transaction_size_million) OVER (ORDER BY Transaction_date)) /LAG(Bitcoin_transaction_size_million)OVER (ORDER BY Transaction_date),3)
END AS percentage_change_of_Bitcoin_trans_size_mil,
CASE
WHEN LAG(Dogecoin_transaction_value_million) OVER (ORDER BY Transaction_date) IS NULL THEN NULL
ELSE round((Dogecoin_transaction_value_million - LAG(Dogecoin_transaction_value_million) OVER (ORDER BY Transaction_date)) /LAG(Dogecoin_transaction_value_million) OVER (ORDER BY Transaction_date),3)
END AS percentage_change_of_doge_trans_value_mil,
CASE
WHEN LAG(Bitcoin_transaction_value_million) OVER (ORDER BY Transaction_date) IS NULL THEN NULL
ELSE round((Bitcoin_transaction_value_million - LAG(Bitcoin_transaction_value_million) OVER (ORDER BY Transaction_date)) /LAG(Bitcoin_transaction_value_million)OVER (ORDER BY Transaction_date),3)
END AS percentage_change_of_Bitcoin_trans_value_mil,
FROM
admazes-da-intern-gcp-dev-2024.airflow_project.comb_table_data
order by Transaction_date;
"""
t9 = BigQueryInsertJobOperator(
     task_id="FINAL_TABLE",
     dag=dag,
      configuration={
         "query":{
             "query": t9_query,
             "writeDisposition": "WRITE_TRUNCATE",
             "use_legacy_sql": False,
              "destinationTable":{
                 "projectId": "admazes-da-intern-gcp-dev-2024",
                 "datasetId": "airflow_project",
                 "tableId": "Final_table"
              }
          }
      }
  )

t1 >> t4
t2 >> t5
t3 >> t6
[t4, t5, t6] >> t7
t7 >> t8
t8 >> t9